{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install awswrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload data to S3\n",
    "\n",
    "First you need to create a bucket for this experiment. Upload the data from the following public location to your own S3 bucket. To facilitate the work of the crawler use two different prefixs (folders): one for the billing information and one for reseller. \n",
    "\n",
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your bucket name\n",
    "your_bucket = 'XXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/billing_sm.csv\n",
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/reseller_sm.csv\n",
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/awswrangler-0.0b2-py3.6.egg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os\n",
    "import awswrangler\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('billing', 'billing_sm.csv')).upload_file('billing_sm.csv')\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('reseller', 'reseller_sm.csv')).upload_file('reseller_sm.csv')\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('python', 'awswrangler-0.0b2-py3.6.egg')).upload_file('awswrangler-0.0b2-py3.6.egg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Crawler\n",
    "\n",
    "To use this csv information in the context of a Glue ETL, first we have to create a Glue crawler pointing to the location of each file. The crawler will try to figure out the data types of each column. \n",
    "\n",
    "1. Create an IAM role GlueCrawlerRole with the policy AWSGlueServiceRole.\n",
    "2. Under Services, go to AWS Glue.\n",
    "3. Under crawlers Add a Crawler : create one pointing to different each S3 locations (one to billing and one to reseller)\n",
    "\n",
    "    3.1 Fill  a Crawler Name: point a Data Store to specific S3 path, Navigate to your bucket and your folder: /billing, click \"Next\"\n",
    "    \n",
    "    3.2 Specify \"Yes\" to add a new Data Store and navigate to your bucket and your folder: /reseller, Click \"Next\" and select \"No\" when asking for add more Data stores, use an existing IAM role \"AWSGlueServiceRole\", add database \"implementationdb\", Click on \"Next\" and \"Finish\"\n",
    "    \n",
    "    3.3 After the crawler is created select \"Run it now\".\n",
    "    \n",
    "\n",
    "After the crawler run you should see two tables has been added for each folder. You can use Athena to inspect the tables and double check the data has been added properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute a query to create a sample View in Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "session = awswrangler.Session()\n",
    "query=('CREATE VIEW resellers_sample AS SELECT *'\n",
    "       'FROM billing where id_reseller '\n",
    "       'in (select distinct id_reseller from reseller TABLESAMPLE BERNOULLI(10))')\n",
    "\n",
    "df = session.pandas.read_sql_athena(\n",
    "    sql=query,\n",
    "    database=\"implementationdb\",\n",
    "    max_result_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
