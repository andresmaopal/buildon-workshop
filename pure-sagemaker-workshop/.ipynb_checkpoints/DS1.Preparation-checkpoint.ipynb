{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload data to S3\n",
    "\n",
    "First you need to create a bucket for this experiment. Upload the data from the following public location to your own S3 bucket. To facilitate the work of the crawler use two different prefixs (folders): one for the billing information and one for reseller. \n",
    "\n",
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your bucket name\n",
    "your_bucket = 'XXXXXXXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/sales-forecast/billing_sm.csv\n",
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/sales-forecast/reseller_sm.csv\n",
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/sales-forecast/awswrangler-0.0b2-py3.6.egg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('billing', 'billing_sm.csv')).upload_file('billing_sm.csv')\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('reseller', 'reseller_sm.csv')).upload_file('reseller_sm.csv')\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('python', 'awswrangler-0.0b2-py3.6.egg')).upload_file('awswrangler-0.0b2-py3.6.egg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Crawler\n",
    "\n",
    "To use this csv information in the context of a Glue ETL, first we have to create a Glue crawler pointing to the location of each file. The crawler will try to figure out the data types of each column. The safest way to do this process is to create one crawler for each table pointing to a different location.\n",
    "\n",
    "1. Create an IAM role GlueCrawlerRole with the policy AWSGlueServiceRole.\n",
    "2. Under Services, go to AWS Glue.\n",
    "3. Under crawlers Add Crawler and two crawlers: create one pointing to each S3 location (one to billing and one to reseller)\n",
    "\n",
    "    3.1 Name: Billing, Data Store, Specific Path in my Account, Navigate to your bucket and your folder Billing, use an existing IAM role AWSGlueServiceRole, add database implementationdb, Next, Finish\n",
    "    \n",
    "    3.2 After the crawler is created select Run it now.\n",
    "    \n",
    "    3.3 Name: Reseller, Data Store, Specific Path in my Account, Navigate to your bucket and your folder Reseller, use an existing IAM role AWSGlueServiceRole, select database implementationdb, Next, Finish\n",
    "    \n",
    "    3.4 After the crawler is created select Run it now.\n",
    "\n",
    "After both crawlers run you should see one table is been adeed for each. You can use Athena to inspect the tables and double check the data is been added properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sample View in Athena\n",
    "\n",
    "When dealing with medium or large datasets, it's a good practice to work on a sample. This will allow you to perform faster experiments regarding feature engineering, data exploration, etc. \n",
    "\n",
    "Under Services > Athena we can create the following view on the query editor that will sample only a 10% of the resellers from the billing dataset.\n",
    "\n",
    "    CREATE VIEW resellers_sample AS\n",
    "    select * from billing where \n",
    "    id_reseller in (select distinct id_reseller from reseller TABLESAMPLE BERNOULLI(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
